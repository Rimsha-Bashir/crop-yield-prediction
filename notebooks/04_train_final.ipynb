{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc21652-fff4-4af9-a767-3d95113f6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083fe89a-ccc7-4ed1-a2b4-593167b280ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/yield_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427f790c-490b-490d-9c49-239b380dc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['country','crop', 'year']\n",
    "\n",
    "numerical = ['average_rain_fall_mm_per_year',\n",
    " 'pesticide_tonnes',\n",
    " 'avg_temp']\n",
    "\n",
    "eta = 0.1\n",
    "max_depth = 7\n",
    "min_child_weight = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ce19a-f5dc-4524-a47c-1a909a69cd6c",
   "metadata": {},
   "source": [
    "## Splitting dataset into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40dbf8bd-2ccf-41f8-a067-8dcdb337daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_train=df_train.reset_index(drop=True)\n",
    "df_test=df_test.reset_index(drop=True)\n",
    "df_val=df_val.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train['yield_hg_ha'].values\n",
    "y_train = df_train.yield_hg_ha.values\n",
    "y_test = df_test.yield_hg_ha.values\n",
    "y_val = df_val.yield_hg_ha.values\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "y_full_train_log = np.log1p(y_full_train)\n",
    "\n",
    "\n",
    "del df_full_train['yield_hg_ha']\n",
    "del df_train['yield_hg_ha']\n",
    "del df_test['yield_hg_ha']\n",
    "del df_val['yield_hg_ha']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d85d0-bb50-4562-8176-2d2376df0802",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867e14de-9f24-4b40-8549-e8171f9c2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform highly skewed numerical features\n",
    "skewed_features = ['pesticide_tonnes', 'average_rain_fall_mm_per_year']\n",
    "for col in skewed_features:\n",
    "    df_full_train[col] = np.log1p(df_full_train[col])\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "    df_val[col] = np.log1p(df_val[col])\n",
    "    df_test[col] = np.log1p(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf5313e-f23e-4001-8d37-9372bfd6a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_full_train[numerical] = scaler.fit_transform(df_full_train[numerical])\n",
    "df_train[numerical] = scaler.fit_transform(df_train[numerical])\n",
    "df_val[numerical] = scaler.transform(df_val[numerical])\n",
    "df_test[numerical] = scaler.transform(df_test[numerical])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278850d-0a49-457c-ae56-1ac5f6383af7",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5441938b-de87-4ec0-9f4f-464248462a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "\n",
    "\n",
    "def xgb_train(df_train, df_val, y_train_log, y_val_log, eta, \n",
    "              num_boost_round, max_depth, min_child_weight):\n",
    "    \n",
    "    dicts_train = df_train.to_dict(orient='records')\n",
    "    dicts_val = df_val.to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts_train)\n",
    "    X_val = dv.transform(dicts_val)\n",
    "\n",
    "    features = dv.get_feature_names_out().tolist()\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train_log, feature_names=features)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val_log, feature_names=features)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "    \n",
    "    xgb_params = {\n",
    "        'eta': eta,                     \n",
    "        'max_depth': max_depth,                \n",
    "        'min_child_weight': min_child_weight,         \n",
    "        'objective': 'reg:squarederror',                        \n",
    "        'eval_metric':['rmse', 'mae'],\n",
    "        'nthreads':8,         \n",
    "        'seed':1,            \n",
    "        'verbosity':0  \n",
    "    }\n",
    "    \n",
    "    \n",
    "    evals_result = {}\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=watchlist,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Predictions in log scale\n",
    "    y_train_pred_log = model.predict(dtrain)\n",
    "    y_val_pred_log = model.predict(dval)\n",
    "\n",
    "    # Convert back to original scale\n",
    "    y_train_pred = np.expm1(y_train_pred_log)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "\n",
    "    # Compute metrics in original scale\n",
    "    df_metrics = pd.DataFrame({\n",
    "    'boost_round': range(num_boost_round),\n",
    "    'train_rmse': evals_result['train']['rmse'],\n",
    "    'val_rmse': evals_result['val']['rmse'],\n",
    "    'train_mae': evals_result['train']['mae'],\n",
    "    'val_mae': evals_result['val']['mae']\n",
    "    })\n",
    "\n",
    "\n",
    "    return dv, model, df_metrics\n",
    "\n",
    "    \n",
    "\n",
    "# Predict function\n",
    "def xgb_predict(df, dv, model):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    X = dv.transform(dicts)\n",
    "\n",
    "    features = dv.get_feature_names_out().tolist()\n",
    "    \n",
    "    d = xgb.DMatrix(X, feature_names=features)\n",
    "    \n",
    "    y_pred = model.predict(d)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "def regression_metrics(y_actual, y_pred):\n",
    "    mse = mean_squared_error(y_actual, y_pred)  # compare with y_val in original units\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0602a740-da25-4c9a-b128-59779d79e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:20827.276730288097\n",
      "Validation MAE:11340.8203125\n",
      "Validation R2:0.9337305426597595\n"
     ]
    }
   ],
   "source": [
    "dv, model, df_metrics = xgb_train(\n",
    "        df_train, df_val, y_train_log, y_val_log,\n",
    "        eta=eta, num_boost_round=200, max_depth=max_depth, min_child_weight=min_child_weight\n",
    "    )\n",
    "    \n",
    "# Predict on validation set\n",
    "y_pred_val_log = xgb_predict(df_val, dv, model)\n",
    "y_pred_val = np.expm1(y_pred_val_log)  # convert back to original units\n",
    "    \n",
    "# Evaluate metrics on val\n",
    "rmse, mae, r2_val = regression_metrics(y_val, y_pred_val)\n",
    "    \n",
    "print(f\"Validation RMSE:{rmse}\")\n",
    "print(f\"Validation MAE:{mae}\")\n",
    "print(f\"Validation R2:{r2_val}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edc55b-9591-4bed-b84a-226abc11f0d6",
   "metadata": {},
   "source": [
    "## Full Train DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2054bc2-95cc-4e71-b5b3-4a7edbda22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train_full(df_train, y_train_log, eta, \n",
    "              num_boost_round, max_depth, min_child_weight):\n",
    "    \n",
    "    dicts_train = df_train.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts_train)\n",
    "\n",
    "    features = dv.get_feature_names_out().tolist()\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train_log, feature_names=features)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'eta': eta,                     \n",
    "        'max_depth': max_depth,                \n",
    "        'min_child_weight': min_child_weight,         \n",
    "        'objective': 'reg:squarederror',                        \n",
    "        'eval_metric': ['rmse', 'mae'],\n",
    "        'nthreads': 8,         \n",
    "        'seed': 1,            \n",
    "        'verbosity': 0  \n",
    "    }\n",
    "\n",
    "    evals_result = {}\n",
    "    watchlist = [(dtrain, 'train')]  \n",
    "\n",
    "    model = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=watchlist,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Gather metrics\n",
    "    df_metrics = pd.DataFrame({\n",
    "        'boost_round': range(num_boost_round),\n",
    "        'train_rmse': evals_result['train']['rmse'],\n",
    "        'train_mae': evals_result['train']['mae']\n",
    "    })\n",
    "\n",
    "    return dv, model, df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6b5e73-872b-4605-818c-d6806652ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:22920.336472224833\n",
      "Test MAE:11930.142578125\n",
      "Test R2:0.9222497344017029\n"
     ]
    }
   ],
   "source": [
    "dv, model, df_metrics = xgb_train_full(\n",
    "        df_full_train, y_full_train_log, eta=eta, num_boost_round=200,\n",
    "        max_depth=max_depth, min_child_weight=min_child_weight\n",
    "    )\n",
    "    \n",
    "# Predict on test set\n",
    "y_pred_test_log = xgb_predict(df_test, dv, model)\n",
    "y_pred_test = np.expm1(y_pred_test_log)  # convert back to original units\n",
    "    \n",
    "# Evaluate metrics on test\n",
    "rmse, mae, r2 = regression_metrics(y_test, y_pred_test)\n",
    "    \n",
    "print(f\"Test RMSE:{rmse}\")\n",
    "print(f\"Test MAE:{mae}\")\n",
    "print(f\"Test R2:{r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdad009-d350-474f-81be-0a7717e2cdb7",
   "metadata": {},
   "source": [
    "## Saving Model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf59762d-f748-4863-8fde-820f6ae1e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file='../model/xgboost_eta=%s_depth=%s_minchild=%s_round=200.bin'%(eta, max_depth, min_child_weight)\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((model,dv), f_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "084a58c5-2d9d-4f0e-9669-2e7871caa0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 04_train_final.ipynb to script\n",
      "[NbConvertApp] Writing 7121 bytes to ../scripts/train.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script 04_train_final.ipynb --output ../scripts/train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
